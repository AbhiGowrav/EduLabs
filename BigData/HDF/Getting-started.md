## Getting started with Big Data

BigData is a term related to extracting meaningful data by analyzing the huge amount of complex, variously formatted data generated at high speed, that cannot be handled, processed by the traditional system.

In this hands-on lab you will perform the following tasks:

- **Exercise 1 : Using Eclipse to Run a Hadoop Application**
- **Exercise 2 : Hortonworks DataFlow using Dockerized Deployment**

## Overview

## Introduction to Big Data

Big data can be defined as a concept used to describe a large volume of data, which are both structured and unstructured, and that gets increased day by day by any system or business. However, it is not the quantity of data, which is essential. The important part is what any firm or organization can do with the data matters a lot. Analysis can be performed on big data for insight and predictions, which can lead to a better decision and reliable strategy in business moves.

## Task 1: Getting started with the environment

In the following task, you will view the pre-deployed resources provided in the environment.

1. In the virtual machine provided on the left side, you can view the resources like Eclipse, Docker is installed.

1. Refer to the **Environment Details** tab for any other lab credentials/details.

1. Click on **Next** from the bottom right corner and follow the instructions to perform the lab 
